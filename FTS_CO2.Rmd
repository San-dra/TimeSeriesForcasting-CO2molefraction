---
title: "CO2 mole fraction at Mauna Loa Observatory"
author: "Sandra Alemayehu"
date: "3/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Laoding Data and Libraries}
library(fBasics)
library(forecast)
library(astsa)
data <- read.csv("C:/Users/sandr/Desktop/FTS_3_11/Datos_CO2.csv", T, ',', dec = '.')
y <- data[,4]
```

## Question 1

### Model 1

**Find at most two time series models, using the Box-Jenkins methodology, for the monthly mean CO2 mole fraction at Mauna Loa Observatory, Hawaii, from March 1958 to February 2019.**

We have monthly data for 61 years, and building a model for the last 10 years should be enough. Thus the number of lags will be 

```{r set_constants, include = F, echo = F}
nlags = 240
s = 12
```

```{r plot_data, fig.align="center",fig.height=4, fig.width=10}
ts.plot(y)
```
```{r Plot_acf_pacf_1}
par(mfrow = c(2,1))
acf(y, nlags)
pacf(y,nlags)
```

The plot shows stationarity in variance, however there is no stationarity in the mean. This is further evidenced by the slow decline of the lags in the ACF towards.
We need to make a difference thus we need to check the Dickey Fuller test and see how many difference we need to make. 


```{r Dickey1, echo=FALSE}
suppressWarnings(nsdiffs(y, m = s, test = c("ocsb")))
ndiffs(y, alpha = 0.05, test = c("adf"))
```
The test above shows that there is no need to make seasonal difference but one difference in the normal. 
Model 1

```{r model1_1, echo=FALSE}
model1 <- arima(y,order = c(0, 1, 0), seasonal = list(order = c(0, 0, 0), period = s))
par(mfrow = c(3,1))
ts.plot(model1$residuals)
acf(model1$residuals, nlags)
pacf(model1$residuals,nlags)

```
```{r Dicky1_1}
suppressWarnings(nsdiffs(model1$residuals, m = s, test = c("ocsb")))
ndiffs(model1$residuals, alpha = 0.05, test = c("adf"))
```
We can see now we no longer need further difference. But our ACF shows some cyclical flow and this might be due to the seasonal nature of the data. So we will first model the seasonal part with the sAR=1 as we have lag 12 out of limit. We will check the residuals and see if our model can be improved.

```{r model1_2, echo=FALSE}
model1 <- arima(y,order = c(0, 1, 0), seasonal = list(order = c(1, 0, 0), period = s))
par(mfrow = c(3,1))
ts.plot(model1$residuals)
acf(model1$residuals, nlags)
pacf(model1$residuals,nlags)
```

With our SARIMA(0,1,0)(1,0,0) still has seasonal lag out of limit in the PACF and ACF. In PACF the 12 and 24 lags are out of limit. But the non-seasonal part is no longer out of limit, except lag 1 in both PACF and ACF. We can improve our model by modeling a moving average of 1 for the regular part. And increasing the AR is seasonal part.

```{r model1_3, echo=FALSE}
model1 <- arima(y,order = c(0, 1, 1), seasonal = list(order = c(3, 0, 0), period = s))
par(mfrow = c(3,1))
ts.plot(model1$residuals)
acf(model1$residuals, nlags)
pacf(model1$residuals,nlags)
```
Having modeled with 2 AR in the seasonal part, we still have lags out of limit. 


```{r shapiro1, echo=FALSE}
shapiro.test(model1$residuals)
```
```{r histogram1, echo=FALSE}
hist(model1$residuals,prob=T,ylim=c(0,1.5),xlim=c(mean(model1$residuals)-3*sd(model1$residuals),mean(model1$residuals)+3*sd(model1$residuals)),col="red")
lines(density(model1$residuals),lwd=2)
mu<-mean(model1$residuals)
sigma<-sd(model1$residuals)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

```{r BoxTest1, echo=FALSE}
model1
Box.test(model1$residuals, lag = 40, type = 'Ljung-Box')
```
The null hypothesis of the Box Test is that the residuals are uncorrelated. The p-value is 0.0003922, preventing us from rejecting this null hypothesis.
The Shapiro test and the plot shows that our residual are normal, and is is white noise thus we can conclude that our residuals are Guassian white noise. 


### Model 2
In the first model only taking difference in the regular part, now we will model taking a difference in the seasonal part as well and see if our model is better. Even though the Dickey Fuller only suggested taking a difference in the regular, it might be that our lags are out of limit due to this. 

Additional, taking only the regular difference resulted in cyclical data and this might be captured by
We also got errors of stationarity in our seasonal part thus this might improve out data.

```{r model2_1, echo=FALSE}
model2 <- arima(y,order = c(0, 1, 0), seasonal = list(order = c(0, 1, 0), period = s))
par(mfrow = c(3,1))
ts.plot(model2$residuals)
acf(model2$residuals, nlags)
pacf(model2$residuals,nlags)
```
```{r Dicky2_1}
suppressWarnings(nsdiffs(model2$residuals, m = s, test = c("ocsb")))
ndiffs(model2$residuals, alpha = 0.05, test = c("adf"))
```
Now that we took a difference in both the regular and seasonal we can see look at the PACF and ACF. We no longer see a cyclical behavious in the ACF. 
We have multiple lags out of limit in PACF for 12, 24, and 36, and just one in ACF. instead of doing AR of 3 for seasonal it is better to model a moving average of 1 which will capture it. 
For the regular part we have one lag out of limit so we will model a moving average of 1 in the regular part as well. 

```{r model2_2, echo=FALSE}
model2 <- arima(y,order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = s))
par(mfrow = c(3,1))
ts.plot(model2$residuals)
acf(model2$residuals, nlags)
pacf(model2$residuals,nlags)
```

With our SARIMA(0,1,1)(0,1,1) it appears that we no longer have lags significantly out limit.

```{r shapiro2, echo=FALSE}
shapiro.test(model2$residuals)
```
```{r histogram2, echo=FALSE}
hist(model2$residuals,prob=T,ylim=c(0,1.5),xlim=c(mean(model2$residuals)-3*sd(model2$residuals),mean(model2$residuals)+3*sd(model2$residuals)),col="red")
lines(density(model2$residuals),lwd=2)
mu<-mean(model2$residuals)
sigma<-sd(model2$residuals)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

```{r BoxTest2, echo=FALSE}
model2
Box.test(model2$residuals, lag = 40, type = 'Ljung-Box')
```
The null hypothesis of the Box Test is that the residuals are uncorrelated. The p-value is 0.2368, preventing us from rejecting this null hypothesis.Thus our model is a good fit and our residuals are white noise. 

The Shapiro test tells use our residuals are not normally distributed but the plot shows that our residual are normal, and is is white noise. 
We can say that our residuals are Guassian white noise, white normality and white noise. Thus also strict white noise and we don't a non-linear model for our data. 



### Model 3

In the second model we took a moving average on both the regular and seasonal. But lets see how our ACF and PACF are after only taking the moving average for seasonal part and model the regular part with a AR.


```{r model3_1, echo=FALSE}
model3 <- arima(y,order = c(0, 1, 0), seasonal = list(order = c(0, 1, 1), period = s))
par(mfrow = c(3,1))
ts.plot(model3$residuals)
acf(model3$residuals, nlags)
pacf(model3$residuals,nlags)
```

With our SARIMA(0,1,0)(0,1,1), we have only few lags out of limit in PACF in the regular data and just one lag in ACF. But we can model an AR of 1 since the others are not significantly out of limit. 

```{r model3_2, echo=FALSE}
model3 <- arima(y,order = c(1, 1, 0), seasonal = list(order = c(0, 1, 1), period = s))
par(mfrow = c(3,1))
ts.plot(model3$residuals)
acf(model3$residuals, nlags)
pacf(model3$residuals,nlags)
```
It appears that there aren't any lags out of bound significantly. The model is significant as the confidence interval for the coefficients doesn't include zero. 

```{r shapiro3, echo=FALSE}
shapiro.test(model3$residuals)
```
```{r histogram3, echo=FALSE}
hist(model3$residuals,prob=T,ylim=c(0,1.5),xlim=c(mean(model3$residuals)-3*sd(model3$residuals),mean(model3$residuals)+3*sd(model3$residuals)),col="red")
lines(density(model3$residuals),lwd=2)
mu<-mean(model3$residuals)
sigma<-sd(model3$residuals)
x<-seq(mu-3*sigma,mu+3*sigma,length=100)
yy<-dnorm(x,mu,sigma)
lines(x,yy,lwd=2,col="blue")
```

```{r BoxTest3, echo=FALSE}
model3
Box.test(model3$residuals, lag = 120, type = 'Ljung-Box')
```
The null hypothesis of the Box Test is that the residuals are uncorrelated. The p-value is 0.06056, just above 0.05 preventing us from rejecting this null hypothesis.Thus our model is a good fit and our residuals are white noise. 

The Shapiro test tells use our residuals are not normally distributed but the plot shows that our residual are normal, and is is white noise. 
We can say that our residuals are Guassian white noise, white normality and white noise. Thus also strict white noise and we don't a non-linear model for our data. 


## Question 2
Forcasting and Evaluating model performance. 

We will be forcasting for 120 months and we will try to do this

```{r Forecasting Variables}
n <- length(y)
n.estimation <- 120
n.forecasting <- n - n.estimation
periods_ahead <- 2
```

We will evaluate out models with recursive forecasting for two period ahead and check the MAPE and MSFE. We are measuring the model error and choosing one with less value in the 

### Evaluating Model 2
SARIMA(0,1,1)(0,1,1)



```{r create matrix}
predicc <- matrix(0, nrow = n.forecasting, ncol = periods_ahead)
real <- matrix(0, nrow = n.forecasting, ncol = 1)
real <- y[(n.estimation + 1) : length(y)]
MSFE <- matrix(0, nrow = periods_ahead, ncol = 1)
MAPE <- matrix(0, nrow = periods_ahead, ncol = 1)

```


```{r Model2Evaluation}
suppressWarnings(for (Periods_ahead in 1 : periods_ahead) {
  for (i in 1 : n.forecasting) {
    aux.y <- y[1 : (n.estimation - Periods_ahead + i)]
    fit <- arima(y, order = c(0, 1, 1), seasonal = list(order = c(0, 1, 1), period = s), method="ML")
    y.pred <- predict(fit, n.ahead = Periods_ahead)
    predicc[i, Periods_ahead] <- (y.pred$pred[Periods_ahead])
  }
  error <- real-predicc[, Periods_ahead]
  MSFE[Periods_ahead] <- mean(error ^ 2)
  MAPE[Periods_ahead] <- mean(abs(error / real)) * 100
})

model1_MAPE <- MAPE
model1_MSFE <- MSFE

```


### Evaluating Model 3
SARIMA(1,1,0)(0,1,1)
```{r emptymatrix}
MSFE <- matrix(0, nrow = periods_ahead, ncol = 1)
MAPE <- matrix(0, nrow = periods_ahead, ncol = 1)
```




```{r Model3Evaluation}

suppressWarnings(for (Periods_ahead in 1 : periods_ahead) {
  for (i in 1 : n.forecasting) {
    aux.y <- y[1 : (n.estimation - Periods_ahead + i)]
    fit <- arima(y, order = c(1, 1, 0), seasonal = list(order = c(0, 1, 1), period = s), method="ML")
    y.pred <- predict(fit, n.ahead = Periods_ahead)
    predicc[i, Periods_ahead] <- (y.pred$pred[Periods_ahead])
  }
  error <- real-predicc[, Periods_ahead]
  MSFE[Periods_ahead] <- mean(error ^ 2)
  MAPE[Periods_ahead] <- mean(abs(error / real)) * 100
})

model2_MAPE <- MAPE
model2_MSFE <- MSFE

model2_MAPE
model2_MSFE

```



